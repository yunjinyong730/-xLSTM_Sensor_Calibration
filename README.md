# xLSTM_Sensor_Calibration

> PatchMLP 문서 흐름 그대로 재구성했음. 수식 표기는 GitHub 수식(GFM/KaTeX) 사용함. 

---

## TL;DR임

- xLSTM, **지수 게이트** 도입 + **메모리 스칼라→행렬 확장**으로 저장/갱신력 크게 상승함  
- **sLSTM**: 지수 입력/망각 게이트 + 정규화자/안정화자 도입 → 새로운 강한 증거 오면 기억 재평가/교체 쉬움  
- **mLSTM**: **행렬 메모리 + 공분산 업데이트**로 **연합 기억** 내장함. 메모리 믹싱 없음 → 병렬화 쉬움  
- 대규모 토큰(예: 300B)에서 퍼플렉서티/스케일링 좋음. 다양한 계열과 경쟁 혹은 우위 보임

---

## 문제의식과 핵심 메시지임

- 전통 LSTM 한계 있음
  1) 저장값 강한 재수정 어려움  
  2) 스칼라 셀이라 저장 용량 작음  
  3) 메모리 믹싱 탓에 완전 병렬화 어려움

- xLSTM 핵심 아이디어 이렇다임
  - 지수 게이팅 + 정규화/안정화로 수치 안정성 확보하면서 강력한 갱신력 얻음  
  - 행렬 메모리 + 공분산 업데이트로 키-값 저장/검색 내장 → 장기·희소 패턴에 강함  
  - Residual 블록으로 깊게 쌓는 구조 채택(Pre/Post up-projection)함

---

## 모델 개요임

> sLSTM(스칼라 메모리) + mLSTM(행렬 메모리)을 Residual 블록으로 감싸 스택한 아키텍처임

### 1) sLSTM (Scalar LSTM with Exponential Gates)임

- 상태 업데이트 식 아래와 같음

$$c_t = f_t\,c_{t-1} + i_t\,z_t,\qquad
n_t = f_t\,n_{t-1} + i_t$$

$$\hat{h}_t = \frac{c_t}{n_t},\qquad
h_t = o_t\,\hat{h}_t$$

- 게이트 정의 이렇다임

$$i_t=\exp(\tilde{i}_t),\quad
f_t \in \{\sigma(\tilde{f}_t),\,\exp(\tilde{f}_t)\},\quad
o_t=\sigma(\tilde{o}_t)$$

- 지수 게이트 강력하나 수치 폭주 위험 있음 → 안정화 상태 $m_t$ 사용해 $i_t', f_t'$ 재정의하여 출력/미분 동등성 유지함  
- 메모리 믹싱은 **헤드 내부** 재귀($R_z,R_i,R_f,R_o$)만 허용함 → 상태 추적 능력 강화됨

### 2) mLSTM (Matrix LSTM with Covariance Memory)임

- 행렬 메모리 $C_t \in \mathbb{R}^{d\times d}$ 사용함. 저장은 공분산 규칙 따름

$$C_t = f_t\,C_{t-1} + i_t\,v_t\,k_t^\top,\qquad
n_t = f_t\,n_{t-1} + i_t\,k_t$$

- 읽기(read) 식은 아래와 같음

$$h_t = o_t \odot \left( \frac{C_t\,q_t}{\max\big(|n_t^\top q_t|,\,1\big)} \right)$$

- BAM/Fast Weights 전통과 연결됨. $f_t$는 감쇠율, $i_t$는 학습률에 해당함  
- 메모리 믹싱 없음 → 완전 병렬화 가능함. 긴 컨텍스트에 유리함

### 3) xLSTM 블록(Residual) & 스택임

- sLSTM 블록: **Post up-projection** 방식(Transformer식) → sLSTM 뒤 게이트드 MLP 붙임  
- mLSTM 블록: **Pre up-projection** 방식(SSM식) → MLP ↑ → mLSTM → MLP ↓ 구성함  
- 고차 비선형 임베딩에서 역사 분리 쉬워져 다음 예측 정확도 오름

---

## 왜 효과적인지임

- 지수 게이트, 새로운 강한 증거 등장 시 기존 기억 가중 기하급수적으로 조정함 → 재평가/교체 쉬움. 정규화자/안정화자로 수치 폭주 방지됨  
- 행렬 메모리, 키-값 직접 저장/검색하는 연합 기억이라 희귀/장기 상관 포착 유리함. 공분산 업데이트가 신호/잡음비 개선함  
- Pre/Post up-projection 설계로 고차에서 비선형 요약 가능 → 히스토리 분리 쉬워지고 예측 정밀해짐

---

## 설계 포인트(실무 체크리스트)임

- 지수 게이트 안정화 필수임 → $m_t$ 기반으로 $i_t', f_t'$ 정의해 출력/그라디언트 보존 + 안정화 달성함  
- sLSTM 메모리 믹싱은 **헤드 내부**로 제한함 → 스택/괄호류 상태 추적에 유리함  
- mLSTM은 믹싱이 없어 **완전 병렬화** 쉬움 → GPU 처리량 높음, 긴 컨텍스트 강함  
- 정규화자 $n_t$ 는 게이트 강도 누적 기록함 → 읽기 시 안정적 스케일 제공함

---

## 실험 결과 요약임

- 데이터/비교군: SlimPajama 등 대규모 토큰(예: 300B) 사용함. 비교: Llama / Mamba / RWKV 등 포함함. 1.3B~ 다양한 크기, 길이 외삽(2k→16k) 검증함  
- 스케일링 법칙 양호함 → 파라미터/데이터 늘려도 성능 이득 일관됨  
- 다수 벤치/도메인에서 경쟁력 또는 우위 확인됨  
- 추론 속도/처리량 측면에서 **선형 시간 + 상수 메모리** 덕에 대배치에 강함. Transformer 대비 배치 확대 시 이점 큼

---

## 어블레이션 인사이트임

- 지수 게이팅 + 행렬 메모리 결합이 성능 핵심 동력임 → 기본 LSTM에서 구성 요소 추가할수록 PPL 꾸준히 하락함  
- 게이트를 입력/히든 의존형으로 둘 때 고정 감쇠/선형 규칙보다 성능 우수함

---

## 메모리·속도 관점임

- 복잡도: 컨텍스트 길이 $L$에 **시간 $\mathcal{O}(L)$**, **메모리 상수**임. RNN이라 KV 캐시 증가 없음  
- 실측: 1.3B 규모에서도 생성 시간 선형, 처리량 우수함. Transformer는 배치 커질수록 메모리 병목 생김

---

## 한계와 향후 과제임

- sLSTM 순차성 존재함 → 완전 병렬화 어려움. 커스텀 CUDA로 완화 가능하나 mLSTM 대비 속도 불리할 수 있음  
- mLSTM 연산비 큼 → $d\times d$ 업데이트/읽기 최적화 여지 큼  
- 하이퍼/초기화 튜닝 여지 남아 있음  
- 극단적 길이/도메인 일반화 추가 검증 필요함

---

## 결론임

- xLSTM, **지수 게이팅** + **행렬 메모리**로 **재평가 쉬운 기억 + 대용량 연합 기억 + 병렬성** 동시에 확보함  
- Residual 블록 스택으로 대규모 모델 구성 시 **스케일링·긴 문맥·처리량** 장점 확실함  
- Transformer/SSM/RNN 전반과 폭넓게 경쟁 혹은 우위 가능함

---

## 부록: 구현 체크리스트(요약)임

- sLSTM
  - 게이트: $i_t=\exp(\tilde{i}_t)$, $f_t=\sigma(\tilde{f}_t)$ 또는 $\exp(\tilde{f}_t)$, $o_t=\sigma(\tilde{o}_t)$ 사용함  
  - 안정화자 $m_t$ 로 $i_t', f_t'$ 재정의 필수임(출력/미분 보존)  
  - 메모리 믹싱은 헤드 내부 재귀($R_z,R_i,R_f,R_o$)만 허용함

- mLSTM
  - 저장: $C_t = f_t C_{t-1} + i_t v_t k_t^\top$  
  - 읽기: $h_t = o_t \odot \big(C_t q_t / \max(|n_t^\top q_t|,1)\big)$  
  - 메모리 믹싱 없음 → 완전 병렬화 가능함. sLSTM 유사 안정화 기법 적용 가능함

- 블록/아키텍처
  - sLSTM = Post up-proj, mLSTM = Pre up-proj, 둘 다 Residual + (옵션) Conv + Gated MLP 구성 추천함

