```markdown
# TimeXer — 외생 변수(Exogenous)를 활용하는 트랜스포머 기반 시계열 예측

> **한 줄 요약**  
> TimeXer는 내생(예측 대상) 시계열은 **패치 단위(Self-Attention)** 로, 외생(보조) 시계열은 **변수 단위(Cross-Attention)** 로 처리하며, **글로벌 토큰**을 매개로 두 정보를 정교하게 결합해 다양한 벤치마크에서 SOTA 성능을 보이는 간단·일반 목적의 트랜스포머 설계입니다. :contentReference[oaicite:0]{index=0}

---

## 목차
- [핵심 아이디어](#핵심-아이디어)
- [문제 정의](#문제-정의)
- [모델 아키텍처](#모델-아키텍처)
  - [내생 임베딩: 패치 + 글로벌 토큰](#내생-임베딩-패치--글로벌-토큰)
  - [외생 임베딩: 변수(시계열) 단일 토큰](#외생-임베딩-변수시계열-단일-토큰)
  - [듀얼 어텐션: 패치-자기어텐션 & 변수-크로스어텐션](#듀얼-어텐션-패치-자기어텐션--변수-크로스어텐션)
  - [출력 & 학습](#출력--학습)
- [왜 이렇게 설계했나?](#왜-이렇게-설계했나)
- [실험 결과 요약](#실험-결과-요약)
- [어블레이션 & 분석](#어블레이션--분석)
- [현실 환경 대응력](#현실-환경-대응력)
- [멀티변수 예측으로의 확장](#멀티변수-예측으로의-확장)
- [복잡도/효율성](#복잡도효율성)
- [한계와 권장 사용처](#한계와-권장-사용처)
- [재현 팁](#재현-팁)
- [인용](#인용)

---

## 핵심 아이디어
- **역할 분리**
  - **내생 (Endogenous)** = 예측 목표. **국소/장기 패턴**에 집중 → 패치 단위 토큰화 후 **Self-Attention**.
  - **외생 (Exogenous)** = 보조 변수. 센서마다 결측·주기·길이 다름 → **시계열 전체를 하나의 변수 토큰**으로 요약 후 **Cross-Attention**으로 주입.
- **글로벌 토큰**: 내생 시계열마다 1개. 외생 정보가 패치로 흘러가기 전 **허브** 역할.

---

## 문제 정의
주어진 내생 시계열 $$x_{1:T}\in\mathbb{R}^{T\times1}$$ 과 $$C$$개의 외생 시계열 $$z^{(i)}_{1:T_{\text{ex}}}\in\mathbb{R}^{T_{\text{ex}}\times1}$$ 로  
미래 $$S$$ 스텝 $$\hat{x}_{T+1:T+S}=F_\theta\!\bigl(x_{1:T},\,z_{1:T_{\text{ex}}}\bigr)$$ 를 예측합니다.  
$$T$$와 $$T_{\text{ex}}$$는 달라도 되므로 현실의 주기/길이 불일치를 자연스럽게 수용합니다. :contentReference[oaicite:1]{index=1}

---

## 모델 아키텍처

### 내생 임베딩: 패치 + 글로벌 토큰
1. 내생 $$x$$를 길이 $$P$$ 의 **비중첩 패치** $$\{s_i\}_{i=1}^N,\,N=\lfloor T/P\rfloor$$ 로 분할  
2. 각 패치를 선형 임베딩 → **패치 토큰** $$P_{\text{en}}\in\mathbb{R}^{N\times D}$$  
3. 전역 정보를 담는 **학습형 글로벌 토큰** $$G_{\text{en}}\in\mathbb{R}^{1\times D}$$ 추가

### 외생 임베딩: 변수(시계열) 단일 토큰
각 외생 $$z^{(i)}$$ 전체를 투영해 **변수 토큰** $$V^{(i)}_{\text{ex}}\in\mathbb{R}^{1\times D}$$ 생성  
→ 결측·주기 불일치에 강하고 계산량 최소화

### 듀얼 어텐션
- **내생 Self-Attention**  
  $$[P_{\text{en}},\,G_{\text{en}}] \;\xrightarrow{\text{Self-Attn}}\; [P_{\text{en}}',\,G_{\text{en}}']$$
- **외생→내생 Cross-Attention**  
  $$Q=G_{\text{en}}',\;\;K=V_{\text{ex}},\;\;V=V_{\text{ex}}$$  
  $$\text{CrossAttn}(Q,K,V)\;\xrightarrow{}\;G_{\text{en}}''$$  
  → 외생 정보가 글로벌 토큰을 경유해 패치로 전달

### 출력 & 학습
최종 $$[P_{\text{en}}^{(L)},\,G_{\text{en}}^{(L)}]$$ 를 선형 변환하여 $$\hat{x}$$ 산출,  
$$\mathcal{L}=\lVert\hat{x}-x_{\text{target}}\rVert_2^2$$ 로 학습

---

## 왜 이렇게 설계했나
- 외생을 패치화하면 **복잡도↑ & 노이즈↑**  
- 변수 단일 토큰은 결측·불일치에 내성  
- **글로벌 토큰**이 외생↔내생 패치 간 **인과적 정보 허브** 역할

---

## 실험 결과 요약
| 데이터셋 | 설정 | TimeXer | 기존 SOTA | 비고 |
|----------|------|---------|-----------|------|
| 전력가격 EPF | 입력 168 → 예측 24 | **최고** | PatchTST, TiDE 등 | 5개 마켓 전부 SOTA |
| ETT/ECL/Traffic/Weather | 입력 96 → 다양한 길이 | **대부분 1위** | TimesNet, iTransformer | |
| ERA5 날씨 3,850 스테이션 | 주기 불일치 환경 | **우수** | Crossformer | |

*Cross-Attention으로 외생을 정교하게 주입해 iTransformer-계열과 PatchTST-계열의 약점을 모두 보완합니다.* :contentReference[oaicite:2]{index=2}

---

## 어블레이션 & 분석
- 외생을 패치화/글로벌 토큰 제거 → **성능 급락**  
- Cross-Attention 대신 단순 결합 → **잡음 유입**  
- 패치 길이 $$P$$ 너무 작으면 **패턴 표현력↓**  
- 어텐션 맵: 내생과 형태 유사 외생에 집중 → 물리적 상관성 확인

---

## 현실 환경 대응력
- **외생 결측/랜덤화**: 성능 소폭 하락  
- **내생 결측**: 성능 급락  
- **주기/길이 불일치**: 변수 토큰화로 보간 불필요  
- **대규모 변수**: 외생·외생 간 Attn을 생략해 메모리/시간 절감

---

## 멀티변수 예측으로의 확장
각 변수를 순차적으로 **내생**으로 두고 나머지는 **외생**으로 설정 → 동일 블록을 **공유**하여 병렬 예측 가능

---

## 복잡도/효율성
- iTransformer: 모든 변수 간 Self-Attn → $$\mathcal{O}(C^2)$$  
- **TimeXer**: 외생↔글로벌만 Cross-Attn → $$\mathcal{O}(C)$$

---

## 한계와 권장 사용처
- 외생 간 상호작용이 중요한 도메인에서는 변형이 필요  
- **권장**: 결측·불일치 많은 센서 데이터, 변수 수가 많은 전력/교통/기상 예측 등

---

## 재현 팁
| 항목 | 권장 설정 |
|------|-----------|
| 패치 길이 $$P$$ | 단기: 24, 장기: 8 또는 16 |
| 옵티마이저 | Adam, lr ≈ $$1{\times}10^{-4}$$ |
| 블록 수 $$L$$ | 1 – 3 |
| 히든 차원 $$D$$ | 128 / 256 / 512 |
| 외생 전처리 | 결측 보간 최소화, 스케일링·클리핑 |

---

## 인용
이 README는 업로드된 논문 *TimeXer* 를 기반으로 작성되었습니다. 구현·데이터·세부 수치는 원문을 참고하세요. :contentReference[oaicite:3]{index=3}
```
